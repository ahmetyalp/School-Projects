{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use HTMLParser in Python standart libraries to scrap IMDB data. I examine the page source I found where title, storyline and recommendations are. <br>\n",
    "Titles are after '<div class=\"title_wrapper\" ...>' <br>\n",
    "Storylines after '<div ... id=\"titleStoryLine\">' <br>\n",
    "Recommandations are after '<div class='rec_item' ..>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from html.parser import HTMLParser\n",
    "import csv\n",
    "import os\n",
    "import math\n",
    "\n",
    "class MyParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.title_begin = 0\n",
    "        self.story_h_line = 0\n",
    "        self.story_begin_line = 0\n",
    "        self.rec_movies = []\n",
    "        self.storyline = \"\"\n",
    "        self.title = \"\"\n",
    "        super().__init__()\n",
    "    \n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == 'div' and len(attrs) > 0 and attrs[0][0] == 'class' and attrs[0][1] == 'title_wrapper':\n",
    "            self.title_begin = self.getpos()[0]\n",
    "        if tag == 'span' and self.story_begin_line == 0  and self.story_h_line > 0 and self.getpos()[0] > self.story_h_line and len(attrs) == 0:\n",
    "            self.story_begin_line = self.getpos()[0]\n",
    "        if tag == 'div' and len(attrs) > 0 and attrs[0][0] == 'class' and attrs[0][1] == 'rec_item':\n",
    "            self.rec_movies.append(attrs[3][1])\n",
    "        if tag == 'div' and len(attrs) > 1 and attrs[1][0] == 'id' and attrs[1][1] == 'titleStoryLine':\n",
    "            self.story_h_line = self.getpos()[0]\n",
    "    def get_title(self):\n",
    "        return self.title.strip()\n",
    "    def handle_data(self, data):\n",
    "        if self.getpos()[0] == self.story_begin_line:\n",
    "            self.storyline = self.storyline +  data\n",
    "        if self.title_begin > 0 and self.getpos()[0] >= self.title_begin and self.title == \"\":\n",
    "            self.title = data.strip()\n",
    "    def get_rec_movies(self):\n",
    "        return self.rec_movies\n",
    "    def get_story_line(self):\n",
    "        return self.storyline.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "I use punctuations file from first project to eliminate punctuations. I translate all letters to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(string):\n",
    "    global dic\n",
    "    string = string.translate(dic)\n",
    "    return string.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Scraping\n",
    "Get HTML text of movies' page and scrap with my HTML parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_contents(imdb_id):\n",
    "    \"\"\"\n",
    "    Gets an imdb id and returns its title, storyline, list of IMDB recommendations respectively.\n",
    "    \"\"\"\n",
    "    x = requests.get('https://www.imdb.com/title/'+imdb_id)\n",
    "    parser = MyParser()\n",
    "    parser.feed(x.text)\n",
    "    parser.close()\n",
    "    return (parser.get_title(), parser.get_story_line(),  parser.get_rec_movies())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation\n",
    "I only use values in document vector that higher than the threshold value. <br>\n",
    "Returns sorted list of IMDB ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(imdb_id):\n",
    "    \"\"\"\n",
    "    Gets an imdb id and returns a list of recommended movie ids for that movie. \n",
    "    \"\"\"\n",
    "    global N\n",
    "    global id_list\n",
    "    scores = []\n",
    "    for id in id_list:\n",
    "        cosine_score = 0.0\n",
    "        for j in tf_idf_above_threshold[imdb_id]: # Only take some scores in calculation\n",
    "            cosine_score += tf_idf[id][j]*tf_idf[imdb_id][j]\n",
    "        scores.append(cosine_score)\n",
    "    rec_movies = list(range(0,N))\n",
    "    rec_movies = sorted(rec_movies , key = lambda x:scores[x], reverse = True)\n",
    "    rec_movies = [id_list[x] for x in rec_movies]\n",
    "    rec_movies.remove(imdb_id) # Get rid of movie itself\n",
    "    return rec_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(rec_movie_ids, relevant_movie_ids, K):\n",
    "    \"\"\"\n",
    "    Gets list of recommended and relevant movie ids and K value.\n",
    "    \n",
    "    Returns precision, recall, F1 values for K respectively. \n",
    "    \"\"\"\n",
    "    rec_movie_ids = rec_movie_ids[:K] # Get top K \n",
    "    print(\"Recommendation by program: \")\n",
    "    print(rec_movie_ids)\n",
    "    print(\"Recommendation by IMDB\")\n",
    "    print(relevant_movie_ids)\n",
    "    precision = len([x for x in rec_movie_ids if x in relevant_movie_ids])/len(rec_movie_ids)\n",
    "    recall = len([x for x in relevant_movie_ids if x in rec_movie_ids])/len(relevant_movie_ids)\n",
    "    print(\"K : \" + str(K))\n",
    "    print(\"Precision : \", precision)\n",
    "    print(\"Recall : \", recall)\n",
    "    try:\n",
    "        f1_score = 2.0*precision*recall/(precision+recall)\n",
    "    except ZeroDivisionError as err: # If both precision and recall is zero than f1_score is undefined.\n",
    "        print(\"Error : \" ,err)\n",
    "        f1_score = math.nan\n",
    "    print(\"F1 Score : \", f1_score)\n",
    "    return (precision,recall,f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold\n",
    "I use threshold. I choose threshold value such that I take ~%85 of nonzero scores after eliminate values below the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.isfile('./movies.txt'): # Save IMDB data to use in future\n",
    "    print(\"Handling IMDB data please wait...\")\n",
    "    with open('./movie_ids.csv' , newline='') as id_file:\n",
    "        file = open('movies.txt' , 'w')\n",
    "        ids = csv.reader(id_file)\n",
    "        for row in ids:\n",
    "            (a,b,c) = get_movie_contents(row[0])\n",
    "            file.write(a)\n",
    "            file.write('\\n')\n",
    "            file.write(b)\n",
    "            file.write('\\n')\n",
    "            for s in c:\n",
    "                file.write(s + ' ')\n",
    "            file.write('\\n')\n",
    "dic = {'\"': ' ', '!': ' ', '^': ' ', '%': ' ', '<': ' ', '+': ' ', '~': ' ', '*': ' ', ';': ' ', ':': ' ', '(': ' ', '?': ' ', '&': ' ', '}': ' ', ']': ' ', '|': ' ', ',': ' ', \"'\": ' ', ')': ' ', '-': ' ', '#': ' ', '`': ' ', '@': ' ', '/': ' ', '$': ' ', '_': ' ', '{': ' ', '.': ' ', '>': ' ', '[': ' ', '\\\\': ' ', '=': ' '}\n",
    "dic = str.maketrans(dic)\n",
    "id_list = [] # list of the ids of the movies\n",
    "file = open('./movies.txt','r')\n",
    "with open('./movie_ids.csv' , newline='') as id_file:\n",
    "    ids = csv.reader(id_file)\n",
    "    for row in ids:\n",
    "        id_list.append(row[0])\n",
    "i = 0\n",
    "N = 0\n",
    "ground_truth = {} # Stores recommended movies by IMDB\n",
    "df = {} \n",
    "tf = {}\n",
    "vocabulary = set()\n",
    "title_plus_storyline = {}\n",
    "s = ''\n",
    "for line in file.readlines():\n",
    "    id_ = id_list[N]\n",
    "    if i == 0:\n",
    "        s = line #Keep the title\n",
    "        i = 1\n",
    "    elif i == 1:\n",
    "        title_plus_storyline[id_] = preprocess(s + ' ' + line) # Merge title and storyline and preprocess\n",
    "        tf[id_] = {}\n",
    "        for x in title_plus_storyline[id_].split(): # create term freqs\n",
    "            if tf[id_].get(x) is None:\n",
    "                tf[id_][x] = 0\n",
    "            tf[id_][x] = tf[id_][x] + 1 \n",
    "            vocabulary.add(x)\n",
    "        i = 2\n",
    "    elif i == 2:\n",
    "        i = 0\n",
    "        line = line.strip()\n",
    "        line = line.split()\n",
    "        ground_truth[id_] = []\n",
    "        for x in line: # save ground truths\n",
    "            ground_truth[id_].append(x)\n",
    "        N = N + 1\n",
    "for val in tf.values(): #calculates document freqs\n",
    "    for key in val.keys():\n",
    "        if df.get(key) is None:\n",
    "            df[key] = 0\n",
    "        df[key] = df[key] + 1\n",
    "vocabulary = list(vocabulary)\n",
    "idf = {}\n",
    "for word in vocabulary: #calculate inverse document freqs\n",
    "    idf[word] = math.log(float(N/df[word]) , 10)\n",
    "\n",
    "tf_idf = {}\n",
    "tf_idf_len = {}\n",
    "threshold = 0.6 #Threshold value\n",
    "tf_idf_above_threshold = {}\n",
    "for i in range(0,N):\n",
    "    id_ = id_list[i]\n",
    "    tf_idf[id_] = []\n",
    "    tf_idf_len[id_] = 0.0\n",
    "    for word in vocabulary:\n",
    "        if tf[id_].get(word) is None: # if a word isn't in the document then its tf_idf score is zero\n",
    "            tf_idf[id_].append(0)\n",
    "        else:\n",
    "            score = (1.0 + math.log(tf[id_][word],10))*idf[word] # calculates scores\n",
    "            tf_idf[id_].append(score)\n",
    "            tf_idf_len[id_] += score**2 #calculations for normalization\n",
    "    tf_idf_above_threshold[id_] = [] # list of words that has higher score than threshold\n",
    "    for j in range(0,len(vocabulary)):\n",
    "        length = math.sqrt(tf_idf_len[id_]) # lenght of the vector\n",
    "        if tf_idf[id_][j] > threshold:\n",
    "            tf_idf_above_threshold[id_].append(j) # save the word\n",
    "            tf_idf[id_][j] = float(tf_idf[id_][j]/length) # normalized vector\n",
    "        else:\n",
    "            tf_idf[id_][j] = 0.0 # ignore values below threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation by program: \n",
      "['tt0075334']\n",
      "Recommendation by IMDB\n",
      "['tt0067221', 'tt0068708', 'tt0067721', 'tt0067744', 'tt0067828', 'tt0069461', 'tt0072217', 'tt0073662', 'tt0080079', 'tt0067977', 'tt0070633', 'tt0080853']\n",
      "K : 1\n",
      "Precision :  0.0\n",
      "Recall :  0.0\n",
      "Error :  float division by zero\n",
      "F1 Score :  nan\n",
      "Recommendation by program: \n",
      "['tt0075334', 'tt0082406']\n",
      "Recommendation by IMDB\n",
      "['tt0067221', 'tt0068708', 'tt0067721', 'tt0067744', 'tt0067828', 'tt0069461', 'tt0072217', 'tt0073662', 'tt0080079', 'tt0067977', 'tt0070633', 'tt0080853']\n",
      "K : 2\n",
      "Precision :  0.0\n",
      "Recall :  0.0\n",
      "Error :  float division by zero\n",
      "F1 Score :  nan\n",
      "Recommendation by program: \n",
      "['tt0075334', 'tt0082406', 'tt0070297']\n",
      "Recommendation by IMDB\n",
      "['tt0067221', 'tt0068708', 'tt0067721', 'tt0067744', 'tt0067828', 'tt0069461', 'tt0072217', 'tt0073662', 'tt0080079', 'tt0067977', 'tt0070633', 'tt0080853']\n",
      "K : 3\n",
      "Precision :  0.0\n",
      "Recall :  0.0\n",
      "Error :  float division by zero\n",
      "F1 Score :  nan\n",
      "Recommendation by program: \n",
      "['tt0075334', 'tt0082406', 'tt0070297', 'tt0014358', 'tt0057611', 'tt0065031', 'tt0053772', 'tt1742023', 'tt0006309', 'tt0087298']\n",
      "Recommendation by IMDB\n",
      "['tt0067221', 'tt0068708', 'tt0067721', 'tt0067744', 'tt0067828', 'tt0069461', 'tt0072217', 'tt0073662', 'tt0080079', 'tt0067977', 'tt0070633', 'tt0080853']\n",
      "K : 10\n",
      "Precision :  0.0\n",
      "Recall :  0.0\n",
      "Error :  float division by zero\n",
      "F1 Score :  nan\n"
     ]
    }
   ],
   "source": [
    "movie_id = 'tt0068481'\n",
    "rec = recommend(movie_id)\n",
    "for K in [1,2,3,10]:\n",
    "    evaluate_recommendations(rec , ground_truth[movie_id] , K)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
